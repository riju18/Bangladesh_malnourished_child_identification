{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split,cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Division</th>\n",
       "      <th>Age at 1st Birth</th>\n",
       "      <th>Child Age</th>\n",
       "      <th>stunting</th>\n",
       "      <th>underweight</th>\n",
       "      <th>wasting</th>\n",
       "      <th>diar</th>\n",
       "      <th>fever</th>\n",
       "      <th>ari</th>\n",
       "      <th>Mother_BMI</th>\n",
       "      <th>Birth_Order</th>\n",
       "      <th>Mother_edu</th>\n",
       "      <th>wealth_index_cat</th>\n",
       "      <th>Father_Edu</th>\n",
       "      <th>residence</th>\n",
       "      <th>sex</th>\n",
       "      <th>currently_working_mot</th>\n",
       "      <th>Breastfeeding</th>\n",
       "      <th>household_no</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.96</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.71</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.66</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>18.41</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.47</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Division  Age at 1st Birth  Child Age  stunting  underweight  wasting  \\\n",
       "0         1                16         13         0            1        1   \n",
       "1         1                18         47         0            1        1   \n",
       "2         1                16         23         0            0        0   \n",
       "3         1                21         11         0            0        0   \n",
       "4         1                15         51         1            1        0   \n",
       "\n",
       "   diar  fever  ari  Mother_BMI  Birth_Order  Mother_edu  wealth_index_cat  \\\n",
       "0   0.0    1.0    1       20.96            2           0                 0   \n",
       "1   0.0    1.0    0       19.71            2           0                 0   \n",
       "2   0.0    0.0    0       20.66            3           0                 0   \n",
       "3   0.0    0.0    0       18.41            1           0                 0   \n",
       "4   0.0    1.0    0       19.47            3           0                 1   \n",
       "\n",
       "   Father_Edu  residence  sex  currently_working_mot  Breastfeeding  \\\n",
       "0         0.0          1    1                    0.0              1   \n",
       "1         0.0          1    1                    0.0              0   \n",
       "2         0.0          1    1                    1.0              1   \n",
       "3         0.0          1    1                    0.0              1   \n",
       "4         0.0          1    1                    1.0              0   \n",
       "\n",
       "   household_no  \n",
       "0             6  \n",
       "1             5  \n",
       "2             5  \n",
       "3             2  \n",
       "4             4  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('finalChildMalnutrition.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(df[['fever','Mother_BMI']].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Division</th>\n",
       "      <th>Age at 1st Birth</th>\n",
       "      <th>Child Age</th>\n",
       "      <th>stunting</th>\n",
       "      <th>underweight</th>\n",
       "      <th>wasting</th>\n",
       "      <th>diar</th>\n",
       "      <th>fever</th>\n",
       "      <th>ari</th>\n",
       "      <th>Mother_BMI</th>\n",
       "      <th>Birth_Order</th>\n",
       "      <th>Mother_edu</th>\n",
       "      <th>wealth_index_cat</th>\n",
       "      <th>Father_Edu</th>\n",
       "      <th>residence</th>\n",
       "      <th>sex</th>\n",
       "      <th>currently_working_mot</th>\n",
       "      <th>Breastfeeding</th>\n",
       "      <th>household_no</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.96</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.71</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.66</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>18.41</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.47</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.91</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.98</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>17.74</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>18.80</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>18.80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Division  Age at 1st Birth  Child Age  stunting  underweight  wasting  \\\n",
       "0         1                16         13         0            1        1   \n",
       "1         1                18         47         0            1        1   \n",
       "2         1                16         23         0            0        0   \n",
       "3         1                21         11         0            0        0   \n",
       "4         1                15         51         1            1        0   \n",
       "5         1                15          5         1            1        0   \n",
       "6         1                19         37         0            0        0   \n",
       "7         1                19         30         0            0        0   \n",
       "8         1                17          4         0            0        0   \n",
       "9         1                17         44         1            1        0   \n",
       "\n",
       "   diar  fever  ari  Mother_BMI  Birth_Order  Mother_edu  wealth_index_cat  \\\n",
       "0   0.0    1.0    1       20.96            2           0                 0   \n",
       "1   0.0    1.0    0       19.71            2           0                 0   \n",
       "2   0.0    0.0    0       20.66            3           0                 0   \n",
       "3   0.0    0.0    0       18.41            1           0                 0   \n",
       "4   0.0    1.0    0       19.47            3           0                 1   \n",
       "5   0.0    0.0    0       26.91            2           0                 0   \n",
       "6   0.0    1.0    1       15.98            1           0                 1   \n",
       "7   0.0    1.0    0       17.74            2           0                 0   \n",
       "8   0.0    0.0    0       18.80            2           1                 0   \n",
       "9   0.0    0.0    0       18.80            1           1                 0   \n",
       "\n",
       "   Father_Edu  residence  sex  currently_working_mot  Breastfeeding  \\\n",
       "0         0.0          1    1                    0.0              1   \n",
       "1         0.0          1    1                    0.0              0   \n",
       "2         0.0          1    1                    1.0              1   \n",
       "3         0.0          1    1                    0.0              1   \n",
       "4         0.0          1    1                    1.0              0   \n",
       "5         0.0          1    1                    0.0              1   \n",
       "6         0.0          1    1                    0.0              0   \n",
       "7         0.0          1    0                    0.0              1   \n",
       "8         0.0          1    1                    0.0              1   \n",
       "9         0.0          1    0                    0.0              1   \n",
       "\n",
       "   household_no  \n",
       "0             6  \n",
       "1             5  \n",
       "2             5  \n",
       "3             2  \n",
       "4             4  \n",
       "5             4  \n",
       "6             7  \n",
       "7             4  \n",
       "8             3  \n",
       "9             3  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(df[['diar','Father_Edu','currently_working_mot']].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X  = df.iloc[:, [1,2,6,7,8,9,10,11,12,13,14,15,16,17,18]].values\n",
    "\n",
    "y_stun = df.iloc[:, 3].values\n",
    "y_underWeight = df.iloc[:, 4].values\n",
    "y_wast = df.iloc[:, 5].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE('minority')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sm, y_wast_sm = smote.fit_sample(X, y_wast)\n",
    "X_sm1, y_underweight_sm = smote.fit_sample(X, y_underWeight)\n",
    "X_sm2, y_stun_sm = smote.fit_sample(X, y_stun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11956, 15)\n",
      "(9454, 15)\n",
      "(8900, 15)\n"
     ]
    }
   ],
   "source": [
    "print(X_sm.shape)\n",
    "print(X_sm1.shape)\n",
    "print(X_sm2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_stun, x_test_stun, y_train_stun, y_test_stun = train_test_split(X_sm2, y_stun_sm, test_size=0.1, random_state=41)\n",
    "x_train_underWeight, x_test_underWeight, y_train_underWeight, y_test_underWeight = train_test_split(X_sm1, y_underweight_sm, test_size=0.1, random_state=41)\n",
    "x_train_wast, x_test_wast, y_train_wast, y_test_wast = train_test_split(X_sm, y_wast_sm, test_size=0.1, random_state=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "x_train_stun = sc.fit_transform(x_train_stun) \n",
    "x_train_underWeight = sc.fit_transform(x_train_underWeight)\n",
    "x_train_wast = sc.fit_transform(x_train_wast)\n",
    "\n",
    "x_test_stun = sc.transform(x_test_stun)\n",
    "x_test_underWeight = sc.transform(x_test_underWeight)\n",
    "x_test_wast = sc.transform(x_test_wast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decission tree classification\n",
    "# -------------------------------\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dClass = DecisionTreeClassifier(criterion='entropy', random_state = 0)\n",
    "dClass1 = DecisionTreeClassifier(criterion='entropy', random_state = 0)\n",
    "dClass2 = DecisionTreeClassifier(criterion='entropy', random_state = 0)\n",
    "\n",
    "dClass.fit(x_train_stun, y_train_stun)\n",
    "dClass1.fit(x_train_underWeight, y_train_underWeight)\n",
    "dClass2.fit(x_train_wast, y_train_wast)\n",
    "\n",
    "y_pred_stun = dClass.predict(x_test_stun)\n",
    "y_pred_underwei = dClass1.predict(x_test_underWeight)\n",
    "y_pred_wast = dClass2.predict(x_test_wast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result of stunting:\n",
      "------------------\n",
      "\n",
      " 67.978 % \n",
      "----------\n",
      "[[302 148]\n",
      " [137 303]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.67      0.68       450\n",
      "           1       0.67      0.69      0.68       440\n",
      "\n",
      "   micro avg       0.68      0.68      0.68       890\n",
      "   macro avg       0.68      0.68      0.68       890\n",
      "weighted avg       0.68      0.68      0.68       890\n",
      "\n",
      "\n",
      "\n",
      "result of underweight:\n",
      "-----------------\n",
      "\n",
      " 70.085 % \n",
      "----------\n",
      "[[309 148]\n",
      " [135 354]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.68      0.69       457\n",
      "           1       0.71      0.72      0.71       489\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       946\n",
      "   macro avg       0.70      0.70      0.70       946\n",
      "weighted avg       0.70      0.70      0.70       946\n",
      "\n",
      "\n",
      "\n",
      "result of wasting:\n",
      "---------------------\n",
      "\n",
      " 85.284 % \n",
      "----------\n",
      "[[517  96]\n",
      " [ 80 503]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.84      0.85       613\n",
      "           1       0.84      0.86      0.85       583\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      1196\n",
      "   macro avg       0.85      0.85      0.85      1196\n",
      "weighted avg       0.85      0.85      0.85      1196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('result of stunting:\\n------------------')\n",
    "#---------------------------------\n",
    "print('\\n',round(accuracy_score(y_test_stun,y_pred_stun)*100,3),'%','\\n----------')\n",
    "print(confusion_matrix(y_test_stun,y_pred_stun))\n",
    "print(classification_report(y_test_stun,y_pred_stun))\n",
    "\n",
    "print('\\n\\nresult of underweight:\\n-----------------')\n",
    "#---------------------------------\n",
    "print('\\n',round(accuracy_score(y_test_underWeight,y_pred_underwei)*100,3),'%','\\n----------')\n",
    "print(confusion_matrix(y_test_underWeight,y_pred_underwei))\n",
    "print(classification_report(y_test_underWeight,y_pred_underwei))\n",
    "\n",
    "print('\\n\\nresult of wasting:\\n---------------------')\n",
    "#---------------------------------\n",
    "print('\\n',round(accuracy_score(y_test_wast,y_pred_wast)*100,3),'%','\\n----------')\n",
    "print(confusion_matrix(y_test_wast,y_pred_wast))\n",
    "print(classification_report(y_test_wast,y_pred_wast))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation with k_fold technique in decissionTree\n",
    "#----------------------------------------------------------\n",
    "\n",
    "allAccuracy_stun = cross_val_score(estimator = dClass,X = x_train_stun, y = y_train_stun, cv = 10)\n",
    "allAccuracy_underwei = cross_val_score(estimator = dClass,X = x_train_underWeight, y = y_train_underWeight, cv = 10)\n",
    "allAccuracy_waste = cross_val_score(estimator = dClass,X = x_train_wast, y = y_train_wast, cv = 10)\n",
    "\n",
    "accuracy_stun_mean = round(allAccuracy_stun.mean()*100,3)\n",
    "accuracy_undrwei_mean = round(allAccuracy_underwei.mean()*100,3)\n",
    "accuracy_waste_mean = round(allAccuracy_waste.mean()*100,3)\n",
    "\n",
    "accuracy_stun_std  = round(allAccuracy_stun.std()*100,3)\n",
    "accuracy_underwei_std  = round(allAccuracy_underwei.std()*100,3)\n",
    "accuracy_waste_std  = round(allAccuracy_waste.std()*100,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC(kernel='rbf')\n",
    "svc1 = SVC(kernel='rbf')\n",
    "svc2 = SVC(kernel='rbf')\n",
    "\n",
    "svc.fit(x_train_stun, y_train_stun)\n",
    "svc1.fit(x_train_underWeight, y_train_underWeight)\n",
    "svc2.fit(x_train_wast, y_train_wast)\n",
    "\n",
    "y_pred_stun_svc = svc.predict(x_test_stun)\n",
    "y_pred_underwei_svc = svc1.predict(x_test_underWeight)\n",
    "y_pred_wast_svc = svc2.predict(x_test_wast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result of stunting:\n",
      "------------------\n",
      "\n",
      " 70.337 % \n",
      "----------\n",
      "[[373  77]\n",
      " [187 253]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.83      0.74       450\n",
      "           1       0.77      0.57      0.66       440\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       890\n",
      "   macro avg       0.72      0.70      0.70       890\n",
      "weighted avg       0.72      0.70      0.70       890\n",
      "\n",
      "\n",
      "\n",
      "result of underweight:\n",
      "-----------------\n",
      "\n",
      " 68.393 % \n",
      "----------\n",
      "[[377  80]\n",
      " [219 270]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.82      0.72       457\n",
      "           1       0.77      0.55      0.64       489\n",
      "\n",
      "   micro avg       0.68      0.68      0.68       946\n",
      "   macro avg       0.70      0.69      0.68       946\n",
      "weighted avg       0.70      0.68      0.68       946\n",
      "\n",
      "\n",
      "\n",
      "result of wasting:\n",
      "---------------------\n",
      "\n",
      " 85.117 % \n",
      "----------\n",
      "[[602  11]\n",
      " [167 416]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.98      0.87       613\n",
      "           1       0.97      0.71      0.82       583\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      1196\n",
      "   macro avg       0.88      0.85      0.85      1196\n",
      "weighted avg       0.88      0.85      0.85      1196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('result of stunting:\\n------------------')\n",
    "#---------------------------------\n",
    "print('\\n',round(accuracy_score(y_test_stun,y_pred_stun_svc)*100,3),'%','\\n----------')\n",
    "print(confusion_matrix(y_test_stun,y_pred_stun_svc))\n",
    "print(classification_report(y_test_stun,y_pred_stun_svc))\n",
    "\n",
    "print('\\n\\nresult of underweight:\\n-----------------')\n",
    "#---------------------------------\n",
    "print('\\n',round(accuracy_score(y_test_underWeight,y_pred_underwei_svc)*100,3),'%','\\n----------')\n",
    "print(confusion_matrix(y_test_underWeight,y_pred_underwei_svc))\n",
    "print(classification_report(y_test_underWeight,y_pred_underwei_svc))\n",
    "\n",
    "print('\\n\\nresult of wasting:\\n---------------------')\n",
    "#---------------------------------\n",
    "print('\\n',round(accuracy_score(y_test_wast,y_pred_wast_svc)*100,3),'%','\\n----------')\n",
    "print(confusion_matrix(y_test_wast,y_pred_wast_svc))\n",
    "print(classification_report(y_test_wast,y_pred_wast_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\This Pc\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\This Pc\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\This Pc\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\This Pc\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\This Pc\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\This Pc\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\This Pc\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\This Pc\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\This Pc\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\This Pc\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\This Pc\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\This Pc\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\This Pc\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\This Pc\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\This Pc\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\This Pc\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\This Pc\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\This Pc\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\This Pc\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\This Pc\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\This Pc\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\This Pc\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\This Pc\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\This Pc\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\This Pc\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\This Pc\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\This Pc\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\This Pc\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\This Pc\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\This Pc\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# cross validation with k_fold technique in svc\n",
    "#----------------------------------------------------------\n",
    "\n",
    "allAccuracy_stun_svc = cross_val_score(estimator = svc,X = x_train_stun, y = y_train_stun, cv = 10)\n",
    "allAccuracy_underwei_svc = cross_val_score(estimator = svc,X = x_train_underWeight, y = y_train_underWeight, cv = 10)\n",
    "allAccuracy_waste_svc = cross_val_score(estimator = svc,X = x_train_wast, y = y_train_wast, cv = 10)\n",
    "\n",
    "accuracy_stun_mean_svc = round(allAccuracy_stun_svc.mean()*100,3)\n",
    "accuracy_undrwei_mean_svc = round(allAccuracy_underwei_svc.mean()*100,3)\n",
    "accuracy_waste_mean_svc = round(allAccuracy_waste_svc.mean()*100,3)\n",
    "\n",
    "accuracy_stun_std_svc  = round(allAccuracy_stun_svc.std()*100,3)\n",
    "accuracy_underwei_std_svc  = round(allAccuracy_underwei_svc.std()*100,3)\n",
    "accuracy_waste_std_svc = round(allAccuracy_waste_svc.std()*100,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naiveBayes classification\n",
    "#--------------------------\n",
    "\n",
    "from sklearn.naive_bayes import  GaussianNB\n",
    "bayes = GaussianNB()\n",
    "bayes1 = GaussianNB()\n",
    "bayes2 = GaussianNB()\n",
    "\n",
    "bayes.fit(x_train_stun, y_train_stun)\n",
    "bayes1.fit(x_train_underWeight, y_train_underWeight)\n",
    "bayes2.fit(x_train_wast, y_train_wast)\n",
    "\n",
    "y_pred_stun_bayes = bayes.predict(x_test_stun)\n",
    "y_pred_underwei_bayes = bayes1.predict(x_test_underWeight)\n",
    "y_pred_wast_bayes = bayes2.predict(x_test_wast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result of stunting:\n",
      "------------------\n",
      "\n",
      " 63.483 % \n",
      "----------\n",
      "[[285 165]\n",
      " [160 280]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.63      0.64       450\n",
      "           1       0.63      0.64      0.63       440\n",
      "\n",
      "   micro avg       0.63      0.63      0.63       890\n",
      "   macro avg       0.63      0.63      0.63       890\n",
      "weighted avg       0.63      0.63      0.63       890\n",
      "\n",
      "\n",
      "\n",
      "result of underweight:\n",
      "-----------------\n",
      "\n",
      " 61.099 % \n",
      "----------\n",
      "[[276 181]\n",
      " [187 302]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.60      0.60       457\n",
      "           1       0.63      0.62      0.62       489\n",
      "\n",
      "   micro avg       0.61      0.61      0.61       946\n",
      "   macro avg       0.61      0.61      0.61       946\n",
      "weighted avg       0.61      0.61      0.61       946\n",
      "\n",
      "\n",
      "\n",
      "result of wasting:\n",
      "---------------------\n",
      "\n",
      " 60.87 % \n",
      "----------\n",
      "[[295 318]\n",
      " [150 433]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.48      0.56       613\n",
      "           1       0.58      0.74      0.65       583\n",
      "\n",
      "   micro avg       0.61      0.61      0.61      1196\n",
      "   macro avg       0.62      0.61      0.60      1196\n",
      "weighted avg       0.62      0.61      0.60      1196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('result of stunting:\\n------------------')\n",
    "#---------------------------------\n",
    "print('\\n',round(accuracy_score(y_test_stun,y_pred_stun_bayes)*100,3),'%','\\n----------')\n",
    "print(confusion_matrix(y_test_stun,y_pred_stun_bayes))\n",
    "print(classification_report(y_test_stun,y_pred_stun_bayes))\n",
    "\n",
    "print('\\n\\nresult of underweight:\\n-----------------')\n",
    "#---------------------------------\n",
    "print('\\n',round(accuracy_score(y_test_underWeight,y_pred_underwei_bayes)*100,3),'%','\\n----------')\n",
    "print(confusion_matrix(y_test_underWeight,y_pred_underwei_bayes))\n",
    "print(classification_report(y_test_underWeight,y_pred_underwei_bayes))\n",
    "\n",
    "print('\\n\\nresult of wasting:\\n---------------------')\n",
    "#---------------------------------\n",
    "print('\\n',round(accuracy_score(y_test_wast,y_pred_wast_bayes)*100,3),'%','\\n----------')\n",
    "print(confusion_matrix(y_test_wast,y_pred_wast_bayes))\n",
    "print(classification_report(y_test_wast,y_pred_wast_bayes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation with k_fold technique in naiveBayes\n",
    "#----------------------------------------------------------\n",
    "\n",
    "allAccuracy_stun_bayes = cross_val_score(estimator = bayes,X = x_train_stun, y = y_train_stun, cv = 10)\n",
    "allAccuracy_underwei_bayes = cross_val_score(estimator = bayes,X = x_train_underWeight, y = y_train_underWeight, cv = 10)\n",
    "allAccuracy_waste_bayes = cross_val_score(estimator = bayes,X = x_train_wast, y = y_train_wast, cv = 10)\n",
    "\n",
    "accuracy_stun_mean_bayes = round(allAccuracy_stun_bayes.mean()*100,3)\n",
    "accuracy_undrwei_mean_bayes = round(allAccuracy_underwei_bayes.mean()*100,3)\n",
    "accuracy_waste_mean_bayes = round(allAccuracy_waste_bayes.mean()*100,3)\n",
    "\n",
    "accuracy_stun_std_bayes  = round(allAccuracy_stun_bayes.std()*100,3)\n",
    "accuracy_underwei_std_bayes  = round(allAccuracy_underwei_bayes.std()*100,3)\n",
    "accuracy_waste_std_bayes  = round(allAccuracy_waste_bayes.std()*100,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomForest classification\n",
    "#--------------------------\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(n_estimators=10, random_state = 0, criterion='entropy')\n",
    "forest1 = RandomForestClassifier(n_estimators=10, random_state = 0, criterion='entropy')\n",
    "forest2 = RandomForestClassifier(n_estimators=10, random_state = 0, criterion='entropy')\n",
    "\n",
    "forest.fit(x_train_stun, y_train_stun)\n",
    "forest1.fit(x_train_underWeight, y_train_underWeight)\n",
    "forest2.fit(x_train_wast, y_train_wast)\n",
    "\n",
    "y_pred_stun_forest = forest.predict(x_test_stun)\n",
    "y_pred_underwei_forest = forest1.predict(x_test_underWeight)\n",
    "y_pred_wast_forest = forest2.predict(x_test_wast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result of stunting:\n",
      "------------------\n",
      "\n",
      " 70.112 % \n",
      "----------\n",
      "[[336 114]\n",
      " [152 288]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.75      0.72       450\n",
      "           1       0.72      0.65      0.68       440\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       890\n",
      "   macro avg       0.70      0.70      0.70       890\n",
      "weighted avg       0.70      0.70      0.70       890\n",
      "\n",
      "\n",
      "\n",
      "result of underweight:\n",
      "-----------------\n",
      "\n",
      " 72.833 % \n",
      "----------\n",
      "[[338 119]\n",
      " [138 351]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.74      0.72       457\n",
      "           1       0.75      0.72      0.73       489\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       946\n",
      "   macro avg       0.73      0.73      0.73       946\n",
      "weighted avg       0.73      0.73      0.73       946\n",
      "\n",
      "\n",
      "\n",
      "result of wasting:\n",
      "---------------------\n",
      "\n",
      " 91.639 % \n",
      "----------\n",
      "[[600  13]\n",
      " [ 87 496]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.98      0.92       613\n",
      "           1       0.97      0.85      0.91       583\n",
      "\n",
      "   micro avg       0.92      0.92      0.92      1196\n",
      "   macro avg       0.92      0.91      0.92      1196\n",
      "weighted avg       0.92      0.92      0.92      1196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('result of stunting:\\n------------------')\n",
    "#---------------------------------\n",
    "print('\\n',round(accuracy_score(y_test_stun,y_pred_stun_forest)*100,3),'%','\\n----------')\n",
    "print(confusion_matrix(y_test_stun,y_pred_stun_forest))\n",
    "print(classification_report(y_test_stun,y_pred_stun_forest))\n",
    "\n",
    "print('\\n\\nresult of underweight:\\n-----------------')\n",
    "#---------------------------------\n",
    "print('\\n',round(accuracy_score(y_test_underWeight,y_pred_underwei_forest)*100,3),'%','\\n----------')\n",
    "print(confusion_matrix(y_test_underWeight,y_pred_underwei_forest))\n",
    "print(classification_report(y_test_underWeight,y_pred_underwei_forest))\n",
    "\n",
    "print('\\n\\nresult of wasting:\\n---------------------')\n",
    "#---------------------------------\n",
    "print('\\n',round(accuracy_score(y_test_wast,y_pred_wast_forest)*100,3),'%','\\n----------')\n",
    "print(confusion_matrix(y_test_wast,y_pred_wast_forest))\n",
    "print(classification_report(y_test_wast,y_pred_wast_forest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation with k_fold technique in randomForest\n",
    "#-------------------------------------------------------\n",
    "\n",
    "allAccuracy_stun_forest = cross_val_score(estimator = forest,X = x_train_stun, y = y_train_stun, cv = 10)\n",
    "allAccuracy_underwei_forest = cross_val_score(estimator = forest,X = x_train_underWeight, y = y_train_underWeight, cv = 10)\n",
    "allAccuracy_waste_forest = cross_val_score(estimator = forest,X = x_train_wast, y = y_train_wast, cv = 10)\n",
    "\n",
    "accuracy_stun_mean_forest = round(allAccuracy_stun_forest.mean()*100,3)\n",
    "accuracy_undrwei_mean_forest = round(allAccuracy_underwei_forest.mean()*100,3)\n",
    "accuracy_waste_mean_forest = round(allAccuracy_waste_forest.mean()*100,3)\n",
    "\n",
    "accuracy_stun_std_forest  = round(allAccuracy_stun_forest.std()*100,3)\n",
    "accuracy_underwei_std_forest  = round(allAccuracy_underwei_forest.std()*100,3)\n",
    "accuracy_waste_std_forest  = round(allAccuracy_waste_forest.std()*100,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\This Pc\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\This Pc\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\This Pc\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# logistic regression\n",
    "#--------------------------\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logReg = LogisticRegression()\n",
    "logReg1 = LogisticRegression()\n",
    "logReg2 = LogisticRegression()\n",
    "\n",
    "logReg.fit(x_train_stun, y_train_stun)\n",
    "logReg1.fit(x_train_underWeight, y_train_underWeight)\n",
    "logReg2.fit(x_train_wast, y_train_wast)\n",
    "\n",
    "y_pred_stun_logReg = logReg.predict(x_test_stun)\n",
    "y_pred_underwei_logReg = logReg1.predict(x_test_underWeight)\n",
    "y_pred_wast_logReg = logReg2.predict(x_test_wast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result of stunting:\n",
      "------------------\n",
      "\n",
      " 63.82 % \n",
      "----------\n",
      "[[288 162]\n",
      " [160 280]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64       450\n",
      "           1       0.63      0.64      0.63       440\n",
      "\n",
      "   micro avg       0.64      0.64      0.64       890\n",
      "   macro avg       0.64      0.64      0.64       890\n",
      "weighted avg       0.64      0.64      0.64       890\n",
      "\n",
      "\n",
      "\n",
      "result of underweight:\n",
      "-----------------\n",
      "\n",
      " 60.782 % \n",
      "----------\n",
      "[[269 188]\n",
      " [183 306]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.59      0.59       457\n",
      "           1       0.62      0.63      0.62       489\n",
      "\n",
      "   micro avg       0.61      0.61      0.61       946\n",
      "   macro avg       0.61      0.61      0.61       946\n",
      "weighted avg       0.61      0.61      0.61       946\n",
      "\n",
      "\n",
      "\n",
      "result of wasting:\n",
      "---------------------\n",
      "\n",
      " 55.184 % \n",
      "----------\n",
      "[[331 282]\n",
      " [254 329]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.54      0.55       613\n",
      "           1       0.54      0.56      0.55       583\n",
      "\n",
      "   micro avg       0.55      0.55      0.55      1196\n",
      "   macro avg       0.55      0.55      0.55      1196\n",
      "weighted avg       0.55      0.55      0.55      1196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('result of stunting:\\n------------------')\n",
    "#---------------------------------\n",
    "print('\\n',round(accuracy_score(y_test_stun,y_pred_stun_logReg)*100,3),'%','\\n----------')\n",
    "print(confusion_matrix(y_test_stun,y_pred_stun_logReg))\n",
    "print(classification_report(y_test_stun,y_pred_stun_logReg))\n",
    "\n",
    "print('\\n\\nresult of underweight:\\n-----------------')\n",
    "#---------------------------------\n",
    "print('\\n',round(accuracy_score(y_test_underWeight,y_pred_underwei_logReg)*100,3),'%','\\n----------')\n",
    "print(confusion_matrix(y_test_underWeight,y_pred_underwei_logReg))\n",
    "print(classification_report(y_test_underWeight,y_pred_underwei_logReg))\n",
    "\n",
    "print('\\n\\nresult of wasting:\\n---------------------')\n",
    "#---------------------------------\n",
    "print('\\n',round(accuracy_score(y_test_wast,y_pred_wast_logReg)*100,3),'%','\\n----------')\n",
    "print(confusion_matrix(y_test_wast,y_pred_wast_logReg))\n",
    "print(classification_report(y_test_wast,y_pred_wast_logReg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\This Pc\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\This Pc\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\This Pc\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\This Pc\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\This Pc\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\This Pc\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\This Pc\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\This Pc\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\This Pc\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\This Pc\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\This Pc\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\This Pc\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\This Pc\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\This Pc\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\This Pc\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\This Pc\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\This Pc\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\This Pc\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\This Pc\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\This Pc\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\This Pc\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\This Pc\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\This Pc\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\This Pc\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\This Pc\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\This Pc\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\This Pc\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\This Pc\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\This Pc\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\This Pc\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# cross validation with k_fold technique in logistic\n",
    "#-------------------------------------------------------\n",
    "\n",
    "allAccuracy_stun_logReg = cross_val_score(estimator = logReg,X = x_train_stun, y = y_train_stun, cv = 10)\n",
    "allAccuracy_underwei_logReg = cross_val_score(estimator = logReg,X = x_train_underWeight, y = y_train_underWeight, cv = 10)\n",
    "allAccuracy_waste_logReg = cross_val_score(estimator = logReg,X = x_train_wast, y = y_train_wast, cv = 10)\n",
    "\n",
    "accuracy_stun_mean_logReg = round(allAccuracy_stun_logReg.mean()*100,3)\n",
    "accuracy_undrwei_mean_logReg = round(allAccuracy_underwei_logReg.mean()*100,3)\n",
    "accuracy_waste_mean_logReg = round(allAccuracy_waste_logReg.mean()*100,3)\n",
    "\n",
    "accuracy_stun_std_logReg  = round(allAccuracy_stun_logReg.std()*100,3)\n",
    "accuracy_underwei_std_logReg  = round(allAccuracy_underwei_logReg.std(),3)\n",
    "accuracy_waste_std_logReg  = round(allAccuracy_waste_logReg.std()*100,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_valid_accuracy = pd.DataFrame({\n",
    "    'DecisionTreeClassifier (avg)': [accuracy_stun_mean,accuracy_undrwei_mean,accuracy_waste_mean],\n",
    "    'support vector machine (avg)': [accuracy_stun_mean_svc,accuracy_undrwei_mean_svc,accuracy_waste_mean_svc],\n",
    "    'naive Bayes (avg)': [accuracy_stun_mean_bayes,accuracy_undrwei_mean_bayes,accuracy_waste_mean_bayes],\n",
    "    'random forest (avg)': [accuracy_stun_mean_forest,accuracy_undrwei_mean_forest,accuracy_waste_mean_forest],\n",
    "    'logistic reg (avg)':[accuracy_stun_mean_logReg,accuracy_undrwei_mean_logReg,accuracy_waste_mean_logReg]\n",
    "},index=['accuracy ( stunting ) %','accuracy ( underweight ) %','accuracy ( wasting ) %'],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DecisionTreeClassifier (avg)</th>\n",
       "      <th>support vector machine (avg)</th>\n",
       "      <th>naive Bayes (avg)</th>\n",
       "      <th>random forest (avg)</th>\n",
       "      <th>logistic reg (avg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy ( stunting ) %</th>\n",
       "      <td>66.866</td>\n",
       "      <td>69.875</td>\n",
       "      <td>62.572</td>\n",
       "      <td>72.122</td>\n",
       "      <td>62.247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy ( underweight ) %</th>\n",
       "      <td>70.111</td>\n",
       "      <td>71.121</td>\n",
       "      <td>63.340</td>\n",
       "      <td>74.988</td>\n",
       "      <td>62.811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy ( wasting ) %</th>\n",
       "      <td>84.740</td>\n",
       "      <td>84.080</td>\n",
       "      <td>60.799</td>\n",
       "      <td>91.023</td>\n",
       "      <td>56.078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            DecisionTreeClassifier (avg)  \\\n",
       "accuracy ( stunting ) %                           66.866   \n",
       "accuracy ( underweight ) %                        70.111   \n",
       "accuracy ( wasting ) %                            84.740   \n",
       "\n",
       "                            support vector machine (avg)  naive Bayes (avg)  \\\n",
       "accuracy ( stunting ) %                           69.875             62.572   \n",
       "accuracy ( underweight ) %                        71.121             63.340   \n",
       "accuracy ( wasting ) %                            84.080             60.799   \n",
       "\n",
       "                            random forest (avg)  logistic reg (avg)  \n",
       "accuracy ( stunting ) %                  72.122              62.247  \n",
       "accuracy ( underweight ) %               74.988              62.811  \n",
       "accuracy ( wasting ) %                   91.023              56.078  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_valid_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard deviation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_valid_std = pd.DataFrame({\n",
    "    'DecisionTreeClassifier (avg)': [accuracy_stun_std,accuracy_underwei_std,accuracy_waste_std],\n",
    "    'support vector machine (avg)': [accuracy_stun_std_svc,accuracy_underwei_std_svc,accuracy_waste_std_svc],\n",
    "    'naive Bayes (avg)': [accuracy_stun_std_bayes,accuracy_underwei_std_bayes,accuracy_waste_std_bayes],\n",
    "    'random forest (avg)': [accuracy_stun_std_forest,accuracy_underwei_std_forest,accuracy_waste_std_forest],\n",
    "    'logistic reg (avg)':[accuracy_stun_std_logReg,accuracy_underwei_std_logReg,accuracy_waste_std_logReg]\n",
    "},index=['std ( stunting ) %','std ( underweight ) %','std ( wasting ) %'],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DecisionTreeClassifier (avg)</th>\n",
       "      <th>support vector machine (avg)</th>\n",
       "      <th>naive Bayes (avg)</th>\n",
       "      <th>random forest (avg)</th>\n",
       "      <th>logistic reg (avg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>std ( stunting ) %</th>\n",
       "      <td>1.260</td>\n",
       "      <td>1.995</td>\n",
       "      <td>1.038</td>\n",
       "      <td>1.830</td>\n",
       "      <td>1.622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std ( underweight ) %</th>\n",
       "      <td>1.906</td>\n",
       "      <td>1.671</td>\n",
       "      <td>1.410</td>\n",
       "      <td>1.413</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std ( wasting ) %</th>\n",
       "      <td>1.033</td>\n",
       "      <td>0.965</td>\n",
       "      <td>1.378</td>\n",
       "      <td>0.863</td>\n",
       "      <td>1.306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       DecisionTreeClassifier (avg)  \\\n",
       "std ( stunting ) %                            1.260   \n",
       "std ( underweight ) %                         1.906   \n",
       "std ( wasting ) %                             1.033   \n",
       "\n",
       "                       support vector machine (avg)  naive Bayes (avg)  \\\n",
       "std ( stunting ) %                            1.995              1.038   \n",
       "std ( underweight ) %                         1.671              1.410   \n",
       "std ( wasting ) %                             0.965              1.378   \n",
       "\n",
       "                       random forest (avg)  logistic reg (avg)  \n",
       "std ( stunting ) %                   1.830               1.622  \n",
       "std ( underweight ) %                1.413               0.014  \n",
       "std ( wasting ) %                    0.863               1.306  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_valid_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "stun = forest.predict(sc.transform(np.array([[18, 47, 0.0, 1.0, 0, 19.71, 2, 0, 0, 0.0, 1, 1, 0.0, 0, 5]])))\n",
    "under = forest1.predict(sc.transform(np.array([[18, 47, 0.0, 1.0, 0, 19.71, 2, 0, 0, 0.0, 1, 1, 0.0, 0, 5]])))\n",
    "wast = forest2.predict(sc.transform(np.array([[18, 47, 0.0, 1.0, 0, 19.71, 2, 0, 0, 0.0, 1, 1, 0.0, 0, 5]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "stunting    = ''\n",
    "underweight = ''\n",
    "wasting     = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in stun:\n",
    "    if i == 0:\n",
    "        stunting = 'not stunting'\n",
    "    else:\n",
    "        stunting = 'stunting'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in under:\n",
    "    if i == 0:\n",
    "        underweight = 'not underweight'\n",
    "    else:\n",
    "        underweight = 'underweight'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in wast:\n",
    "    if i == 0:\n",
    "        wasting = 'not wasting'\n",
    "    else:\n",
    "        wasting = 'wasting'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not stunting\n",
      "underweight\n",
      "wasting\n"
     ]
    }
   ],
   "source": [
    "print(stunting)\n",
    "print(underweight)\n",
    "print(wasting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
